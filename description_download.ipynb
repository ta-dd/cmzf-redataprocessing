{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting description of offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet('df.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_read.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_indices=df.index[~df.index.isin(df_desc_read.index)]\n",
    "desc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_indices.drop_duplicates()\n",
    "desc_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector_description={}\n",
    "\n",
    "for i in range(len(desc_indices)):\n",
    "    base_url = 'https://www.sreality.cz/api/cs/v2/estates/{}'.format(desc_indices[i])\n",
    "\n",
    "    r = requests.get(base_url)\n",
    "\n",
    "    #print(\"starting sleep\")\n",
    "    #sleep(randint(0,2))\n",
    "\n",
    "    if r.status_code==404:\n",
    "        break\n",
    "    \n",
    "    elif r.status_code==200:\n",
    "        r_dict=r.json()\n",
    "        r_dict[\"hash_id\"]=desc_indices[i]\n",
    "\n",
    "        collector_description[i]=r_dict\n",
    "        \n",
    "        print(f\"Description {i} was scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_individual = {}\n",
    "\n",
    "for page, r_dict in collector_description.items():\n",
    "        \n",
    "        info_relevant = pd.Series(dtype=\"object\")\n",
    "        info_relevant[\"description\"]=r_dict[\"text\"][\"value\"]\n",
    "\n",
    "        r_dict_values=pd.DataFrame(r_dict[\"items\"], columns =['type', 'name', 'value'])\n",
    "\n",
    "        info_relevant[\"price\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Cena\"]\n",
    "        info_relevant[\"price_note\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Poznámka k ceně\"]\n",
    "        info_relevant[\"price_per_sqm\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Cena za m²\"]\n",
    "        info_relevant[\"id_order\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"ID zakázky\"]\n",
    "        info_relevant[\"date_update\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Aktualizace\"]\n",
    "        info_relevant[\"building_type\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Stavba\"]\n",
    "        info_relevant[\"availability\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Stav\"]\n",
    "        info_relevant[\"building_condition\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Stav objektu\"]\n",
    "        info_relevant[\"building_location\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Umístění objektu\"]\n",
    "        info_relevant[\"building_floor_type\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Typ domu\"]\n",
    "        info_relevant[\"building_floor\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Podlaží\"]\n",
    "        info_relevant[\"date_moving_in\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Datum nastěhování\"]\n",
    "        info_relevant[\"area_build_up\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Plocha zastavěná\"]\n",
    "        info_relevant[\"garage\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Garáž\"]\n",
    "        info_relevant[\"parking\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Parkování\"]\n",
    "\n",
    "        if sum(r_dict_values['name'] == \"Voda\")>0:\n",
    "                index_nr=int(r_dict_values.index[r_dict_values['name'] == \"Voda\"].tolist()[0])\n",
    "                r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Voda\"][index_nr][0][\"value\"]\n",
    "                del index_nr\n",
    "\n",
    "        if sum(r_dict_values['name'] == \"Topení\")>0:\n",
    "                index_nr=int(r_dict_values.index[r_dict_values['name'] == \"Topení\"].tolist()[0])\n",
    "                r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Topení\"][index_nr][0][\"value\"]\n",
    "                del index_nr\n",
    "\n",
    "        if sum(r_dict_values['name'] == \"Doprava\")>0:\n",
    "                index_nr=int(r_dict_values.index[r_dict_values['name'] == \"Doprava\"].tolist()[0])\n",
    "                r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Doprava\"][index_nr][0][\"value\"]\n",
    "                del index_nr\n",
    "\n",
    "        if sum(r_dict_values['name'] == \"Telekomunikace\")>0:\n",
    "                index_nr=int(r_dict_values.index[r_dict_values['name'] == \"Telekomunikace\"].tolist()[0])\n",
    "                r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Telekomunikace\"][index_nr][0][\"value\"]\n",
    "                del index_nr\n",
    "\n",
    "        if sum(r_dict_values['name'] == \"Plyn\")>0:\n",
    "                index_nr=int(r_dict_values.index[r_dict_values['name'] == \"Plyn\"].tolist()[0])\n",
    "                r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Plyn\"][index_nr][0][\"value\"]\n",
    "                del index_nr\n",
    "\n",
    "        info_relevant[\"energy_efficient_rating\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Energetická náročnost budovy\"]\n",
    "        info_relevant[\"lift\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Výtah\"]\n",
    "        info_relevant[\"equipped\"]=r_dict_values[\"value\"][r_dict_values[\"name\"]==\"Vybavení\"]\n",
    "\n",
    "        description_individual[r_dict[\"hash_id\"]] = info_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_individual[r_dict[\"hash_id\"]] = info_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = pd.concat(description_individual).unstack()\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_full = pd.concat([df_desc, df_desc_read])\n",
    "df_desc_full.to_parquet('df_desc_full.gzip')  \n",
    "#df_desc.to_parquet('df_desc.gzip')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version of scraping - proxies and multiple requests at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fp.fp import FreeProxy\n",
    "import gevent\n",
    "from gevent import monkey, pool\n",
    "#https://stackoverflow.com/questions/15322701/gevent-pool-with-nested-web-requests\n",
    "#https://pypi.org/project/free-proxy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = FreeProxy(country_id=['DE', \"CZ\", \"BR\"]).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=np.add(\"https://www.sreality.cz/api/cs/v2/estates/\", desc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey.patch_all()\n",
    "\n",
    "jobs = []\n",
    "links = []\n",
    "p = pool.Pool(10)\n",
    "\n",
    "add\n",
    "\n",
    "urls = [\n",
    "    'http://www.google.com', \n",
    "    # ... another 100 urls\n",
    "]\n",
    "    \n",
    "def get_jsons(url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        r_dict = r.json()\n",
    "        r_dict[\"hash_id\"]=desc_indices[i]\n",
    "\n",
    "        collector_description[i]=r_dict\n",
    "        \n",
    "for url in urls:\n",
    "    jobs.append(p.spawn(get_jsons, url))\n",
    "gevent.joinall(jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a02a01f4637964553a3d9a76be7cbdd74d3a9321504b5f055e54f87e7bbe80de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
